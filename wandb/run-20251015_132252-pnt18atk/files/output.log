Map: 100%|██████████████████████| 20400/20400 [00:05<00:00, 3630.95 examples/s]
Map: 100%|████████████████████████| 5100/5100 [00:01<00:00, 3899.48 examples/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "D:\Finrapt\intent-classification using bert\train_bert.py", line 64, in <module>
    training_args = TrainingArguments(
        output_dir="./bert_intent_model",
    ...<11 lines>...
        greater_is_better=True,
    )
  File "<string>", line 135, in __init__
  File "D:\Finrapt\intent-classification using bert\intentbert\Lib\site-packages\transformers\training_args.py", line 1811, in __post_init__
    self.device
  File "D:\Finrapt\intent-classification using bert\intentbert\Lib\site-packages\transformers\training_args.py", line 2355, in device
    return self._setup_devices
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\karth\AppData\Local\Programs\Python\Python313\Lib\functools.py", line 1026, in __get__
    val = self.func(instance)
  File "D:\Finrapt\intent-classification using bert\intentbert\Lib\site-packages\transformers\training_args.py", line 2225, in _setup_devices
    raise ImportError(
    ...<2 lines>...
    )
ImportError: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`
